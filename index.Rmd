---
title: "Portfolio Reginald van Putt"
author: "Reginald van Putt"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    orientation: columns
    
date: "2024-02-21"
---
```{r variabels, echo=FALSE}
# Loading in libraries
library(flexdashboard)
library(readr)
library(lubridate)
library(ggplot2)
library(tidyverse)
library(spotifyr)
library(compmus)
library(agricolae)

# Set default chunk options for all plots
knitr::opts_chunk$set(fig.width = 5, fig.height = 4)

id <- "3224ef21d8e245689234aa11d3f2e919"
secret <-"f83518a285bd4bdfbfd77bdda440df7e"
Sys.setenv(SPOTIFY_CLIENT_ID = id)
Sys.setenv(SPOTIFY_CLIENT_SECRET = secret)
access_token <- get_spotify_access_token()
```

```{r circshift}
library(tidyverse)
library(spotifyr)
library(compmus)

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )


```

```{r loading_playlists, echo=FALSE}
#science
pb_features = get_playlist_audio_features("","1dDP0J8kZlyQJ1kw2heuqN") #1
pb_features_2 = get_playlist_audio_features("","5f67hG4cT4vuCbpp2ZJSAC") #2
bs_features = get_playlist_audio_features("","55RF4Rd8rbn4cYKS5fCn2r") #1
bs_features_2 = get_playlist_audio_features("","4gud4X0Q6RV9M2tioEMOvy") #2
medicine_features = get_playlist_audio_features("","5BTPZghhEMr9e6mfGHmv0A") #1
biology_features = get_playlist_audio_features("","2ZyiCXQK1GUCfp33TSOQO6") #1
ai_features = get_playlist_audio_features("","61qvD51DpYY12Sh0GDsmwl") #1
ai_features_2 = get_playlist_audio_features("","2ESdPa7Lsat6szfqcb8TqG") #2
ai_features_3 = get_playlist_audio_features("","05BS3494bYcIokpptZbpgg") #3

#technical uni
ce_features = get_playlist_audio_features("","0ZgkUJVQ5FjavIZBp7zDK7") #1
id_features = get_playlist_audio_features("","01HKzQnzQ5XLn5OefshdIx") #1
me_features = get_playlist_audio_features("","1kZBSsmIMAUocJgM6Dm32F") #1
se_features = get_playlist_audio_features("","4jD1Ua5umx6PTvqhPxD6Qg") #1
me_features_2 = get_playlist_audio_features("","2yIbLUOhrdCSnYJJqUIC9l") #2


#social sciences
cs_features = get_playlist_audio_features("","1xAbFlGMk4NeTcHlXVxNIT") #1
psychology_features = get_playlist_audio_features("","7lN3BZW8AhOzpLpyPY5FqA") #1
sw_features = get_playlist_audio_features("","7FfkG5ZbE9IhpJNOHBqRZM") #1
cs_mmd_features = get_playlist_audio_features("","7bK5sUCOoSwURe0qHZSfLM") #1
education_features = get_playlist_audio_features("","6lUVL6Tq0RRUPqSdjP3ChC") #1
soc_features = get_playlist_audio_features("","0e5Xnkt5CG4DhnpvUtlsAy") #1

#humanities
musicology_features = get_playlist_audio_features("","2GNR2qLtjanP6VtxKmIERI") #1
musicology_features_2 = get_playlist_audio_features("","2Cmef8ivNr7eIby2eYDInj") #2
art_features = get_playlist_audio_features("","4eRCLFaLG2PcT3RcJpEVA5") #1


```

```{r faculty_dividing, echo=FALSE}
sci = "Faculty of Science"
hum = "Faculty of Humanities"
med = "Faculty of Medicine"
tech = "Technical University studies"
soc = "Social and Behavior studies"

final_data <-
  bind_rows(
    #science
    pb_features |> mutate(bachelor = "Psychobiology", faculty = sci),
    pb_features_2 |> mutate(bachelor = "Psychobiology", faculty = sci),
    bs_features |> mutate(bachelor = "Biomedical science", faculty = sci),
    bs_features_2 |> mutate(bachelor = "Biomedical science", faculty = sci),
    biology_features |> mutate(bachelor = "Biology", faculty = sci),
    ai_features |> mutate(bachelor = "Artifical intelligence", faculty = sci),
    ai_features_2 |> mutate(bachelor = "Artifical intelligence", faculty = sci),
    ai_features_3 |> mutate(bachelor = "Artifical intelligence", faculty = sci), #music = FALSE
    medicine_features |> mutate(bachelor = "Medicine", faculty = sci),
    
    #technical uni
    ce_features |> mutate(bachelor = "Civil engineering", faculty = tech),
    id_features |> mutate(bachelor = "Industrial engineering", faculty = tech),
    me_features |> mutate(bachelor = "Mechanical engineering", faculty = tech),
    se_features |> mutate(bachelor = "Software engineering", faculty = tech), #music = FALSE
    me_features_2 |> mutate(bachelor = "Mechanical engineering", faculty = tech), #music = FALSE
    
    #social sciences
    cs_features |> mutate(bachelor = "Communication science", faculty = soc),
    psychology_features |> mutate(bachelor = "Psychology", faculty = soc),
    sw_features |> mutate(bachelor = "Social works", faculty = soc),
    cs_mmd_features |> mutate(bachelor = "Communication and multimedia design", faculty = soc), #music = TRUE
    education_features |> mutate(bachelor = "Education in primary school", faculty = soc), #music = FALSE
    soc_features |> mutate(bachelor = "Sociology", faculty = soc), #music = FALSE
    
    
    #humanities
    musicology_features |> mutate(bachelor = "Musicology", faculty = hum), #music = TRUE
    musicology_features_2 |> mutate(bachelor = "Musicology", faculty = hum), #music = TRUE
    art_features |> mutate(bachelor = "Art and Music", faculty = hum)

    
  )
```

### Key analysis

#### Low
```{r key analysis}
#Lowest valence song

low_valence <-
  get_tidy_audio_analysis("0oL9JFFf33CZP47Kg30U7e") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

low_valence |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  ggtitle("Lowest valence song") +
  theme(plot.caption = element_text(hjust = 0, margin = margin(t = 10))) +
  labs(caption = "This is the song with the lowest valence of the group 'Faculty of Science'.\n It is shown here in the form of a keygram")

```

#### High
```{r}

#Highest valence song

high_valence <-
  get_tidy_audio_analysis("3gY6tiCNsuVi6s8kPV6aQg") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

high_valence |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  ggtitle("Highest valence song") +
  theme(plot.caption = element_text(hjust = 0, margin = margin(t = 10))) +
  labs(caption = "This is the song with the higest valence of the group 'Faculty of Science'.\n It is shown here in the form of a keygram")

```

#### Random
```{r average}
random_average <-
  get_tidy_audio_analysis("6SG8lh7fWQ2bahP5WBYePn") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

random_average |> 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  ggtitle("Random song") +
  theme(plot.caption = element_text(hjust = 0, margin = margin(t = 10))) +
  labs(caption = "This is a random song of the group 'Faculty of Science'.\n It is shown here in the form of a keygram")

```
 
***
The keygrams are quit interesting to compare. The lowest valence song shows a vertical band between 150 and 200 seconds. Meaning that there are more keys being used in that time period compared to the rest. Throughout the song the keys that are used the majority of the time are kind of the same. but the quantity/certainty of it differs a bit.
For the highest valence song it's quite different. there are not a lot of keys that are used but the keys that are used are really stable though the whole song. For the random song there is a lot of uniformity throught the song, but some slight differences such as in the intro and 2 (probably) bridges of sort.

### Chord analysis

#### Low
```{r chord_analysis, echo=FALSE}
#Lowest valence song
# Chord analysis tab
low_valence <-
  get_tidy_audio_analysis("0oL9JFFf33CZP47Kg30U7e") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

low_valence |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  ggtitle("Lowest valence song") +
  theme(plot.caption = element_text(hjust = 0, margin = margin(t = 10))) +
  labs(caption = "This is the song with the lowest valence of the group 'Faculty of Science'.\n It is shown here in the form of a chordogram.")

```

#### High
```{r}

#Highest valence song

high_valence <-
  get_tidy_audio_analysis("3gY6tiCNsuVi6s8kPV6aQg") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

high_valence |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  ggtitle("Highest valence song") +
  theme(plot.caption = element_text(hjust = 0, margin = margin(t = 10))) +
  labs(caption = "This is the song with the higest valence of the group 'Faculty of Science'.\n It is shown here in the form of a chordogram.")

```

#### Random
```{r}
random_average <-
  get_tidy_audio_analysis("6SG8lh7fWQ2bahP5WBYePn") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

random_average |> 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  ggtitle("Random song") +
  theme(plot.caption = element_text(hjust = 0, margin = margin(t = 10))) +
  labs(caption = "This is a random song of the group 'Faculty of Science'.\n It is shown here in the form of a chordogram.")

```


***

There seem to be a very big overlap between chords used in all three songs. Almost (if not all) chords seem to be the same (if looking at the blue-est parts of the chordgram). This surprised me since the valence of these songs is quite different and not all songs are of the same genre (so not just generic pop songs). 

### Introduction
Welcome to my portfolio,

I'm Reginald van Putt and this is my portfolio for the course Computational Musicology (UvA). In this portfolio I will investigate a corpus that I have created with help of my peers and friends. The corpus exists off the top 5 songs of people from all kinds of bachelors. With this corpus I'm trying to investigate whether or not there is a significant difference in study directions in terms of music taste. Specifically looking at the valence, energy and genre of songs. 

*Why?*

The reason why I wanted to investigate this is because I quite often ask people about their music taste and I have done a few courses from different faculties and it seemed to me that different faculties (i.e. FNWI vs AI) have quite different tastes in music. So I that's why I wanted to analyse more data and see if there is a significant difference.


### Visualization


```{r make_plot}
final_data |>                    # Start with awards.
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) |>
  ggplot(                     # Set up the plot.
    aes(
      x = valence,
      y = energy,
      size = loudness,
      colour = faculty
    )
  ) +
  geom_point() +              # Scatter plot.
  geom_rug(linewidth = 0.1) + # Add 'fringes' to show data distribution.
  geom_text(                  # Add text labels from above.
    aes(
      x = valence,
      y = energy,
      label = label
    ),
    data = 
      tibble(
        label = c("", ""), #top and bottom labels
        category = c("Edisons", "Grammys"),
        valence = c(0.104, 0.0339),
        energy = c(0.992, 0.00166)
      ),
    colour = "black",         # Override colour (not mode here).
    size = 3,                 # Override size (not loudness here).
    hjust = "left",           # Align left side of label with the point.
    vjust = "center",         # Align vertical center of label with the point.
    nudge_x = 0.02            # Nudge the label slightly right.
  ) +
  facet_wrap(~ faculty) +    # Separate charts per playlist.
  scale_x_continuous(         # Fine-tune the x axis.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),   # Use grid-lines for quadrants only.
    minor_breaks = NULL       # Remove 'minor' grid-lines.
  ) +
  scale_y_continuous(         # Fine-tune the y axis in the same way.
    limits = c(0, 1),
    breaks = c(0, 0.50, 1),
    minor_breaks = NULL
  ) +
  scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Paired"        # Name of the palette is 'Paired'.
  ) +
  scale_size_continuous(      # Fine-tune the sizes of each point.
    trans = "exp",            # Use an exp transformation to emphasise loud.
    guide = "none"            # Remove the legend for size.
  ) +
  theme_light() +             # Use a simpler theme.
  labs(                       # Make the titles nice.
    x = "Valence",
    y = "Energy",
    title = "Top 5 songs for different bachelors",
    #colour = "Bachelor"
  )
```

***
This is a temporary graph that shows all the data I have incorperated in my corpus untill now. I have more data to incorperate (but this takes a lot of time) and I keep receiving more data through google forms and the canvas discussions. For now this is the layout and format I have chosen to use. On the x-axis you can see the valence and on the y-axis the energy of the songs. The songs plotted are the top 5 songs of many peers and friends, the colors are divided based on their bachelor and the graphs are divided based on faculty/direction of the bachelor. This might change in the future but I still have not decided how to split all bachelors/data. 



### Split visualisation




### Statistical analysis

```{r statistcal_analysis}

#final_data %>%
  #group_by(faculty) %>%
  #select(valence, energy, faculty, bachelor) %>%
  #summarize(mean_valence = mean(valence), mean_energy = mean(energy), sd_valence = sd(valence), sd_energy = sd(energy))

anova_result_1 <- aov(energy ~ faculty, data = final_data)
anova_result_2 <- aov(valence ~ faculty, data = final_data)

#summary(anova_result_1)
#summary(anova_result_2)

#tukey_result_1 <- HSD.test(anova_result_1, "faculty", group = TRUE) #energy
tukey_result_1 <- HSD.test(anova_result_2, "faculty", group = TRUE) #valence

# Access the "statistics" component
statistics <- tukey_result_1$statistics

# Access the "parameters" component
parameters <- tukey_result_1$parameters

# Access the "means" component
means <- tukey_result_1$means

# Access the "groups" component
groups <- tukey_result_1$groups

print(tukey_result_1)
#print(groups)
#print(statistics)

```


### Chromagram

```{r chromagram}
#chromagram 1
outlier <-
  get_tidy_audio_analysis("1oDCK7PW72XEZ1pE5rh87A") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

outlier_duration = duration

outlier |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() +
  ggtitle("The outlier") +
  theme(plot.caption = element_text(hjust = 0, margin = margin(t = 10))) +
  labs(caption = "This is the chromagram of a song that is an outlier, meaning it is far away from all other songs of the corpus in terms of valence and energy. ") 
  #theme(plot.margin = margin(1, 1, 1, 1, "cm")) +
  #theme(plot.background = element_rect(fill = "white", colour = "black")) +
  #theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5))

#chromagram 2
normal_song <-
  get_tidy_audio_analysis("6fl6EkGqKlpZECkys1iDsq") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

normal_song |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |> 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() +
  ggtitle("'Average song'") +
  theme(plot.caption = element_text(hjust = 0, margin = margin(t = 10))) +
    labs(caption = "This is the chromagram of a song that is quite average, meaning it is pretty much in the middle off all other songs of the corpus in terms of valence and energy. ") 

  #theme(plot.margin = margin(1, 1, 1, 1, "cm")) +
  #theme(plot.background = element_rect(fill = "white", colour = "black")) +
  #theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5))
```

***
The reason that the left song has lower energy and valence might be due to the lower frequency of notes, it looks like the amount of notes is quite a bit lower then in the right song / average song. Secondly the valence might be lower because of the fact that the outlier song is mostly minor while the average song is mostly major (according to spotify). Which you might be able to see looking at the chords played througout the song.

P.S. I know that the graphs are not of the same size, I have spend an hour and a half trying to fix that and I could not do it. I'm not planning on using chromagrams in my final portfolio if not manditory so I did not want to spend more time then 2 hours on fixing the sizes of graphs.


### Discussion/conclusion

I have not yet had the time to do a statistic analysis (and I have also not added all the data yet) so I have no clear conclusion yet. For now with the naked eye it seems like there is no significant difference between different groups (excluding the Faculty of Medicine because of the low sample size). 





